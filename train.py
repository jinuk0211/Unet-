# -*- coding: utf-8 -*-
"""train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DKPSg9J6MZcXWTqhKPquttlxGabb48-_
"""

!pip install utils

import torch
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tqdm import tqdm
import torch.nn as nn
import torch.optim as optim
from unet_model import unet
from utils import load_checkpoint,save_checkpoint,get_loaders,check_accuracy,save_predictions_as_imgs,

# hyperparameter 설정
lr = 1e-4
device = 'cuda' if torch.cuda.is_available() else 'cpu'
batchsize =32
epochs = 200
num_workers = 2
# 데이터를 로드할 때 병렬로 데이터를 읽어오는 프로세스의 수를 지정하는 parameter
image_width =240
image_height = 160
pin_memory = True
# dataloader 클래스에서 사용 gpu로 데이터 전송전 호스트 메모리에서 gpu 메모리로 복사할지 여부
load_model = True
# 저장된 모델 가중치를 불러와서 이어서 학습하거나 추론에 사용할 수 있습니다.
train_imgdir = 'data/train_dir/'
train_maskdir = 'data/mask_dir/'
val_imgdir = 'data/val_images/'
val_maskdir = 'data/val_masks/'

def train_fn(loader,model,optimizer,loss_fn,scaler):
  loop = tqdm(loader)
  #loader = torch.utils.data , Dataloader의 instance dataloader의 argument는 만든 dataset
  for batch_idx, (data,targets) in enumerate(loop):
    targets = targets.float().unsqueeze(1).to(device = device)
  #data 불러오는 과정 targets 등
    #forward pass
    with torch.cuda.amp.autocast():
      # 실행되는 코드 블록은 자동으로 FP16 형식으로 연산이 수행 16-bit floating point
      #메모리 사용량 적어지는 대신 정밀도 낮아짐
      predictions =  model(data) # f.cross_entropy(logits,yb) 와 유사
      loss = loss_fn(predictions,targets)

    #backward pass
    optimizer.zero_grad() #초기값 -
    scaler.scale(loss).backward() #gradient 소실 방지 scaler
    scaler.step(optimizer)
    scaler.update()
def main():
  train_transform = A.Compose(
      [A.Resize(height =image_height,width=image_width),
       A.Rotate(limit=35,p=1.0),  #0~35의 randn에서 angle 결정, 100%확률 적용
       A.HorizontalFlip(p=0.5), #50%확률로 가로 뒤집기
       A.VerticalFlip(p=0.1),
       A.Normalize(mean=[0.0,0.0,0.0],#이미지 데이터 정규화
                   std=[1.0,1.0,1.0],
                   max_pixel_value=255.0),ToTensorV2()#이미지를 tensor화시킴
      ])
  val_transform =  A.Compose(
      [
       A.Resize(height =image_height,width=image_width),
       A.Normalize(mean=[0.0,0.0,0.0],#이미지 데이터 정규화
                   std=[1.0,1.0,1.0],
                   max_pixel_value=255.0,),ToTensorV2()#이미지를 tensor화시킴
      ])
  model =unet(in_channels=3,out_channels=1).to(device)
  loss_fn = nn.BCEWithLogitsLoss() #with logits loss 인 이유 = sigmoid안함,
  # softmax는 binary x crossentropy
  optimizer = optim.Adam(model.parameters(),lr=lr)

#  https://www.kaggle.com/c/carvana-imag... dataset
  train_loader, val_loader = get_loaders(
      train_imgdir,
      train_maskdir,
      val_imgdir,
      val_maskdir,
      batchsize,
      train_transform,
      val_transform,
      num_workers,
      pin_memory,
  )
  scaler = torch.cuda.amp.GradScaler()
  for epoch in range(epochs):
    train_fn(train_loader,model,optimizer,loss_fn,scaler)

if __name__ == "__main__":
  main()

